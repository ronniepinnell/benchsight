# Portal/Admin Developer Handoff

**Role:** Admin Portal Developer  
**Version:** 2.0  
**Date:** December 30, 2025

---

## Your Mission

Build a web-based admin portal that provides:
1. Complete database management and monitoring
2. ETL execution and monitoring
3. Data quality validation and reporting
4. Log viewing and error tracking
5. Dimension table management (CRUD)
6. Game data upload and processing
7. System health dashboards

---

## Quick Start

### 1. Get the Codebase
```bash
unzip benchsight_COMPLETE_FULL.zip
cd benchsight_COMPLETE_FULL
```

### 2. Understand the Architecture
```
Portal â†â†’ Supabase API â†â†’ PostgreSQL Database
                â†“
         Python Scripts (ETL, Loaders)
                â†“
         CSV Files (data/output/)
                â†“
         Raw Excel Files (data/raw/)
```

### 3. Key Components You'll Manage

| Component | Location | Purpose |
|-----------|----------|---------|
| Database | Supabase | 98 tables + logs |
| ETL | `etl.py` | Process raw â†’ CSV |
| Loader | `scripts/load_all_tables.py` | CSV â†’ Supabase |
| Logs | `logs/` + `log_*` tables | Audit trail |
| Config | `config/config_local.ini` | Credentials |
| Tests | `tests/` | 326 validation tests |

---

## Portal Features Specification

### 1. DATABASE HEALTH DASHBOARD

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATABASE HEALTH                           Last Check: 2 min agoâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   TABLES    â”‚  â”‚    ROWS     â”‚  â”‚    SIZE     â”‚             â”‚
â”‚  â”‚     96      â”‚  â”‚   120,000   â”‚  â”‚    45 MB    â”‚             â”‚
â”‚  â”‚   âœ… OK     â”‚  â”‚   âœ… OK     â”‚  â”‚   âœ… OK     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                 â”‚
â”‚  RECENT ACTIVITY                                                â”‚
â”‚  â”œâ”€ 10:30 AM - ETL completed (4 games)                         â”‚
â”‚  â”œâ”€ 10:15 AM - Data load successful (24,639 rows)              â”‚
â”‚  â””â”€ 09:00 AM - Scheduled validation passed                     â”‚
â”‚                                                                 â”‚
â”‚  ALERTS                                                         â”‚
â”‚  âš ï¸ 1 duplicate key found in fact_events (non-critical)        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Implementation:

```javascript
// Get table counts
async function getTableStats() {
  const { data } = await supabase.rpc('get_all_table_counts');
  return data;
}

// Get recent ETL runs
async function getRecentRuns() {
  const { data } = await supabase
    .from('log_etl_runs')
    .select('*')
    .order('started_at', { ascending: false })
    .limit(10);
  return data;
}

// Get unresolved errors
async function getAlerts() {
  const { data } = await supabase
    .from('v_unresolved_errors')
    .select('*');
  return data;
}
```

### 2. TABLE BROWSER

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TABLE BROWSER                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TABLES (96)           â”‚  dim_player (337 rows)                 â”‚
â”‚  â”œâ”€ Dimensions (44)    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚  â”œâ”€ dim_player  337 â”‚  â”‚ player_id | player_name | position  â”‚
â”‚  â”‚  â”œâ”€ dim_team     26 â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  â”‚  â”œâ”€ dim_schedule 562â”‚  â”‚ P001      â”‚ John Smith  â”‚ C        â”‚
â”‚  â”‚  â””â”€ ...             â”‚  â”‚ P002      â”‚ Jane Doe    â”‚ LW       â”‚
â”‚  â”œâ”€ Facts (51)         â”‚  â”‚ ...       â”‚ ...         â”‚ ...      â”‚
â”‚  â”‚  â”œâ”€ fact_events 5833â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚  â”œâ”€ fact_shifts 672 â”‚                                        â”‚
â”‚  â”‚  â””â”€ ...             â”‚  [Export CSV] [Edit] [Delete Selected] â”‚
â”‚  â””â”€ Logs (5)           â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Implementation:

```javascript
// Browse any table
async function browseTable(tableName, page = 1, pageSize = 50) {
  const from = (page - 1) * pageSize;
  const to = from + pageSize - 1;
  
  const { data, count } = await supabase
    .from(tableName)
    .select('*', { count: 'exact' })
    .range(from, to);
    
  return { data, count, page, pageSize };
}

// Export to CSV
async function exportTable(tableName) {
  const { data } = await supabase.from(tableName).select('*');
  return convertToCSV(data);
}
```

### 3. DIMENSION TABLE EDITOR

Allow CRUD operations on dimension tables:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EDIT: dim_event_type                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  event_type_id: [EVT015    ]  (auto-generated)                 â”‚
â”‚  event_type:    [Deflection ]                                  â”‚
â”‚  description:   [Puck redirected by player's stick or body   ] â”‚
â”‚  parent_type:   [Shot â–¼]                                       â”‚
â”‚  active:        [âœ“]                                            â”‚
â”‚                                                                 â”‚
â”‚  [Cancel] [Save]                                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Implementation:

```javascript
// Add new dimension record
async function addDimRecord(tableName, record) {
  const { data, error } = await supabase
    .from(tableName)
    .insert([record])
    .select();
    
  if (error) throw error;
  
  // Log the change
  await logChange('INSERT', tableName, null, record);
  
  return data;
}

// Update dimension record
async function updateDimRecord(tableName, id, updates) {
  const primaryKey = getPrimaryKey(tableName);
  
  // Get old values for audit
  const { data: oldRecord } = await supabase
    .from(tableName)
    .select('*')
    .eq(primaryKey, id)
    .single();
  
  const { data, error } = await supabase
    .from(tableName)
    .update(updates)
    .eq(primaryKey, id)
    .select();
    
  if (error) throw error;
  
  // Log the change
  await logChange('UPDATE', tableName, oldRecord, data[0]);
  
  return data;
}

// Delete dimension record
async function deleteDimRecord(tableName, id) {
  const primaryKey = getPrimaryKey(tableName);
  
  // Get old values for audit
  const { data: oldRecord } = await supabase
    .from(tableName)
    .select('*')
    .eq(primaryKey, id)
    .single();
  
  const { error } = await supabase
    .from(tableName)
    .delete()
    .eq(primaryKey, id);
    
  if (error) throw error;
  
  // Log the change
  await logChange('DELETE', tableName, oldRecord, null);
}

// Log all changes for audit
async function logChange(operation, tableName, oldValues, newValues) {
  await supabase.from('log_data_changes').insert([{
    table_name: tableName,
    operation: operation,
    old_values: oldValues,
    new_values: newValues,
    changed_by: getCurrentUser(),
    changed_at: new Date().toISOString()
  }]);
}
```

### 4. FILE UPLOAD & ETL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UPLOAD & PROCESS                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  UPLOAD NEW DATA                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚     Drag & drop files here or click to browse             â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚     Supported: .xlsx, .csv                                â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  PENDING FILES                                                  â”‚
â”‚  â”œâ”€ game_19001_tracking.xlsx (2.3 MB) [Process] [Remove]       â”‚
â”‚  â””â”€ BLB_Tables_updated.xlsx (500 KB) [Process] [Remove]        â”‚
â”‚                                                                 â”‚
â”‚  OPTIONS                                                        â”‚
â”‚  â˜ Run validation after processing                             â”‚
â”‚  â˜ Auto-load to Supabase on success                            â”‚
â”‚  â˜‘ Send notification on completion                             â”‚
â”‚                                                                 â”‚
â”‚  [Process All]                                                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Backend API Endpoints Needed:

```python
# Flask/FastAPI backend endpoints

@app.post("/api/upload")
async def upload_file(file: UploadFile):
    """Upload file to processing queue"""
    # Save to data/raw/pending/
    filepath = save_uploaded_file(file)
    return {"status": "uploaded", "path": filepath}

@app.post("/api/etl/run")
async def run_etl(game_ids: List[str] = None):
    """Run ETL pipeline"""
    # Call etl.py
    result = subprocess.run(
        ["python", "etl.py"] + (["--games", ",".join(game_ids)] if game_ids else []),
        capture_output=True
    )
    return {"status": "completed", "output": result.stdout}

@app.post("/api/loader/run")
async def run_loader(tables: List[str] = None, operation: str = "upsert"):
    """Run data loader"""
    cmd = ["python", "scripts/load_all_tables.py", f"--{operation}"]
    if tables:
        for table in tables:
            subprocess.run(cmd + ["--table", table])
    else:
        subprocess.run(cmd)
    return {"status": "completed"}

@app.get("/api/etl/status")
async def get_etl_status():
    """Get current ETL status"""
    # Check for running processes
    # Return progress if running
    pass
```

### 5. LOG VIEWER

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOG VIEWER                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Filter: [All â–¼] [Last 24h â–¼] [Search...          ] [Apply]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“‹ ETL RUNS                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Run ID          â”‚ Status  â”‚ Tables â”‚ Rows   â”‚ Duration   â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ etl_20251229... â”‚ âœ… OK   â”‚ 96     â”‚ 24,639 â”‚ 31s        â”‚ â”‚
â”‚  â”‚ etl_20251228... â”‚ âš ï¸ PART â”‚ 95     â”‚ 24,100 â”‚ 45s        â”‚ â”‚
â”‚  â”‚ etl_20251227... â”‚ âŒ FAIL â”‚ 12     â”‚ 0      â”‚ 5s         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“‹ ERRORS                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ âš ï¸ Duplicate key in fact_events (EV1896901594)           â”‚ â”‚
â”‚  â”‚    Occurred: 2025-12-29 19:04:55                          â”‚ â”‚
â”‚  â”‚    [View Details] [Mark Resolved]                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Implementation:

```javascript
// Get ETL runs
async function getETLRuns(filters = {}) {
  let query = supabase
    .from('log_etl_runs')
    .select('*')
    .order('started_at', { ascending: false });
    
  if (filters.status) {
    query = query.eq('status', filters.status);
  }
  if (filters.after) {
    query = query.gte('started_at', filters.after);
  }
  
  return query;
}

// Get table load details for a run
async function getRunDetails(runId) {
  const { data } = await supabase
    .from('log_etl_tables')
    .select('*')
    .eq('run_id', runId);
  return data;
}

// Get errors
async function getErrors(resolved = false) {
  const { data } = await supabase
    .from('log_errors')
    .select('*')
    .eq('resolved', resolved)
    .order('created_at', { ascending: false });
  return data;
}

// Resolve error
async function resolveError(errorId, notes) {
  await supabase.rpc('resolve_error', {
    error_id: errorId,
    resolved_by: getCurrentUser(),
    resolution_notes: notes
  });
}
```

### 6. TEST RESULTS VIEWER

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TEST RESULTS                          Last Run: 10 min ago     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SUMMARY                                                        â”‚
â”‚  â”œâ”€ Total Tests: 326                                           â”‚
â”‚  â”œâ”€ Passed: 326 âœ…                                             â”‚
â”‚  â”œâ”€ Failed: 0                                                  â”‚
â”‚  â””â”€ Pass Rate: 100%                                            â”‚
â”‚                                                                 â”‚
â”‚  BY CATEGORY                                                    â”‚
â”‚  â”œâ”€ Referential Integrity: 45/45 âœ…                            â”‚
â”‚  â”œâ”€ Business Logic: 89/89 âœ…                                   â”‚
â”‚  â”œâ”€ Data Quality: 112/112 âœ…                                   â”‚
â”‚  â””â”€ Deployment: 80/80 âœ…                                       â”‚
â”‚                                                                 â”‚
â”‚  [Run Tests Now] [View Full Report] [Export]                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Backend:

```python
@app.post("/api/tests/run")
async def run_tests():
    """Run pytest suite"""
    result = subprocess.run(
        ["python", "-m", "pytest", "tests/", "-v", "--json-report"],
        capture_output=True
    )
    # Parse and store results
    return parse_test_results(result)

@app.get("/api/tests/results")
async def get_test_results():
    """Get latest test results"""
    return supabase.from('log_test_results').select('*').order('run_at', descending=True).limit(1)
```

### 7. DATA VALIDATION PANEL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA VALIDATION                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  INTEGRITY CHECKS                                               â”‚
â”‚  â”œâ”€ Referential Integrity: âœ… All FKs valid                    â”‚
â”‚  â”œâ”€ Primary Key Uniqueness: âš ï¸ 1 duplicate found               â”‚
â”‚  â”œâ”€ Null Constraints: âœ… No unexpected nulls                   â”‚
â”‚  â””â”€ Data Types: âœ… All valid                                   â”‚
â”‚                                                                 â”‚
â”‚  BUSINESS RULES                                                 â”‚
â”‚  â”œâ”€ Goals Match Official: âœ… 4/4 games match                   â”‚
â”‚  â”œâ”€ Events in Shifts: âš ï¸ 58 events without shift              â”‚
â”‚  â”œâ”€ Linked Events Valid: âœ… All links valid                    â”‚
â”‚  â””â”€ Player Stats Sum: âœ… Totals match                          â”‚
â”‚                                                                 â”‚
â”‚  DETAILS                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Issue: 58 events have shift_key containing 'nan'          â”‚ â”‚
â”‚  â”‚ Impact: Minor - events still usable                        â”‚ â”‚
â”‚  â”‚ Games: 18969, 18977, 18981, 18987                         â”‚ â”‚
â”‚  â”‚ [View Events] [Auto-fix] [Ignore]                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  [Run Full Validation] [Export Report]                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8. UPLOAD NEW TABLES (SCHEMA EXTENSION)

Allow users to upload entirely new dimension or fact tables:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CREATE NEW TABLE                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TABLE TYPE: [Dimension â–¼]                                     â”‚
â”‚  TABLE NAME: dim_[                    ]                        â”‚
â”‚                                                                 â”‚
â”‚  UPLOAD CSV TO DEFINE SCHEMA                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Drop CSV here to auto-detect columns                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  DETECTED COLUMNS                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Column       â”‚ Type     â”‚ Primary Key â”‚ Nullable          â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚  â”‚ shot_zone_id â”‚ TEXT     â”‚ â˜‘           â”‚ â˜                 â”‚ â”‚
â”‚  â”‚ zone_name    â”‚ TEXT     â”‚ â˜           â”‚ â˜                 â”‚ â”‚
â”‚  â”‚ x_min        â”‚ DECIMAL  â”‚ â˜           â”‚ â˜‘                 â”‚ â”‚
â”‚  â”‚ x_max        â”‚ DECIMAL  â”‚ â˜           â”‚ â˜‘                 â”‚ â”‚
â”‚  â”‚ danger_level â”‚ INTEGER  â”‚ â˜           â”‚ â˜                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  [Preview SQL] [Create Table] [Create & Load Data]             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Implementation:

```javascript
// Generate CREATE TABLE SQL from CSV
function generateCreateTableSQL(tableName, columns) {
  const colDefs = columns.map(col => {
    let def = `    "${col.name}" ${col.type}`;
    if (col.primaryKey) def += ' PRIMARY KEY';
    if (!col.nullable) def += ' NOT NULL';
    return def;
  });
  
  return `CREATE TABLE ${tableName} (\n${colDefs.join(',\n')}\n);`;
}

// Execute via Supabase
async function createTable(sql) {
  // Need to use Supabase Management API or direct SQL
  // This requires service role key
  const { error } = await supabase.rpc('exec_sql', { sql });
  return !error;
}
```

---

## Python Scripts Reference

### Data Loader Commands

```bash
# Load ALL tables (98 tables)
python scripts/load_all_tables.py

# Load with upsert (handles duplicates)
python scripts/load_all_tables.py --upsert

# Dry run (preview only)
python scripts/load_all_tables.py --dry-run

# Load single table
python scripts/load_all_tables.py --table dim_player --upsert

# Skip dimension tables
python scripts/load_all_tables.py --skip-dims --upsert
```

### Flexible Loader (with logging)

```bash
# Show config
python scripts/flexible_loader_with_logging.py --show-config

# Test connection
python scripts/flexible_loader_with_logging.py --test-connection

# Full load with replace
python scripts/flexible_loader_with_logging.py --scope full --operation replace

# Single table upsert
python scripts/flexible_loader_with_logging.py --scope table --table fact_events --operation upsert

# With Supabase logging
python scripts/flexible_loader_with_logging.py --scope full --operation replace --log-to-supabase

# View last run
python scripts/flexible_loader_with_logging.py --show-last-run
```

### ETL Commands

```bash
# Run full ETL
python etl.py

# ETL specific games
python etl.py --games 18969,18977

# ETL with validation
python etl.py --validate

# ETL dry run
python etl.py --dry-run
```

### Test Commands

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test file
python -m pytest tests/test_deployment_readiness.py -v

# Run with coverage
python -m pytest tests/ --cov=src

# Generate HTML report
python -m pytest tests/ --html=reports/test_report.html
```

---

## Database Management SQL

### Clear All Data (Keep Schema)

```sql
-- Run sql/06_TRUNCATE_ALL_DATA.sql
-- Or individually:
TRUNCATE TABLE fact_events CASCADE;
TRUNCATE TABLE fact_shifts CASCADE;
-- etc.
```

### Recreate Schema

```sql
-- Run sql/05_FINAL_COMPLETE_SCHEMA.sql
-- This drops and recreates all 98 tables
```

### Useful Admin Queries

```sql
-- Table row counts
SELECT * FROM get_all_table_counts();

-- Recent ETL runs
SELECT * FROM v_recent_runs;

-- Daily statistics
SELECT * FROM v_daily_run_stats;

-- Table load performance
SELECT * FROM v_table_load_stats;

-- Unresolved errors
SELECT * FROM v_unresolved_errors;

-- Run summary
SELECT get_run_summary('etl_run_20251229_123456_abc12345');

-- Clean old logs (keep 30 days)
SELECT * FROM cleanup_old_logs(30);

-- Database size
SELECT 
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname || '.' || tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname || '.' || tablename) DESC;
```

---

## Logging Tables Schema

### log_etl_runs
| Column | Type | Description |
|--------|------|-------------|
| run_id | TEXT PK | Unique run identifier |
| started_at | TIMESTAMPTZ | Start time |
| completed_at | TIMESTAMPTZ | End time |
| status | TEXT | success/partial/failed |
| total_tables | INTEGER | Tables processed |
| successful_tables | INTEGER | Tables succeeded |
| failed_tables | INTEGER | Tables failed |
| total_rows | INTEGER | Rows loaded |
| duration_seconds | DECIMAL | Total duration |
| environment | TEXT | dev/prod |
| triggered_by | TEXT | manual/scheduled/api |

### log_etl_tables
| Column | Type | Description |
|--------|------|-------------|
| id | SERIAL PK | Auto ID |
| run_id | TEXT FK | Links to run |
| table_name | TEXT | Table loaded |
| status | TEXT | success/failed |
| rows_before | INTEGER | Count before |
| rows_after | INTEGER | Count after |
| rows_inserted | INTEGER | New rows |
| rows_updated | INTEGER | Updated rows |
| rows_deleted | INTEGER | Deleted rows |
| duration_seconds | DECIMAL | Table duration |
| error_message | TEXT | Error if failed |

### log_errors
| Column | Type | Description |
|--------|------|-------------|
| id | SERIAL PK | Auto ID |
| run_id | TEXT | Related run |
| table_name | TEXT | Related table |
| error_type | TEXT | Type of error |
| error_message | TEXT | Message |
| error_details | JSONB | Full context |
| stack_trace | TEXT | Python traceback |
| resolved | BOOLEAN | Is resolved |
| resolved_by | TEXT | Who resolved |
| resolved_at | TIMESTAMPTZ | When resolved |
| resolution_notes | TEXT | How fixed |

---

## Security Considerations

### API Keys

```
ANON_KEY: For read-only public access (dashboards)
SERVICE_ROLE_KEY: For admin operations (portal backend)
```

**NEVER expose SERVICE_ROLE_KEY to frontend!**

### Portal Authentication

Implement proper auth:
```javascript
// Use Supabase Auth
const { data: { user } } = await supabase.auth.getUser();

// Check admin role
if (!user || !user.app_metadata?.role === 'admin') {
  throw new Error('Unauthorized');
}
```

### Audit Trail

Log all admin actions:
```javascript
async function logAdminAction(action, details) {
  await supabase.from('log_admin_actions').insert([{
    user_id: getCurrentUser(),
    action: action,
    details: details,
    timestamp: new Date().toISOString(),
    ip_address: getClientIP()
  }]);
}
```

---

## Deployment Architecture

### Recommended Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FRONTEND (React/Next.js)                                       â”‚
â”‚  - Admin Dashboard UI                                           â”‚
â”‚  - Table browser                                                â”‚
â”‚  - Log viewer                                                   â”‚
â”‚  - File upload                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKEND API (FastAPI/Flask)                                    â”‚
â”‚  - ETL orchestration                                            â”‚
â”‚  - File processing                                              â”‚
â”‚  - Script execution                                             â”‚
â”‚  - Admin operations                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUPABASE                                                       â”‚
â”‚  - PostgreSQL Database                                          â”‚
â”‚  - Auth                                                         â”‚
â”‚  - Storage (for file uploads)                                   â”‚
â”‚  - Realtime subscriptions                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Future Considerations

### ML/CV Integration
- Add tables for tracking data (player positions, puck tracking)
- Create pipelines for model predictions (xG, xA)
- Store model outputs alongside traditional stats

### NHL Data Integration
- Add NHL API connector
- Map NHL player IDs to internal IDs
- Import historical NHL data for comparison

### Scaling
- Consider read replicas for dashboards
- Implement caching layer (Redis)
- Use background job queue (Celery) for ETL

---

## Resources

- Schema: `sql/05_FINAL_COMPLETE_SCHEMA.sql`
- Logging Tables: `sql/02_CREATE_LOGGING_TABLES.sql`
- Loader Script: `scripts/load_all_tables.py`
- Config: `config/config_loader.py`
- Tests: `tests/` directory

---

## Questions?

See `prompts/portal_dev_prompt.md` for a prompt to start a new Claude chat with full context.
