<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ETL/Data Engineer Handoff - BenchSight</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; color: #333; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #34495e; margin-top: 30px; }
        h3 { color: #7f8c8d; }
        code { background: #f4f4f4; padding: 2px 6px; border-radius: 3px; font-family: Monaco, monospace; }
        pre { background: #2d2d2d; color: #f8f8f2; padding: 15px; border-radius: 5px; overflow-x: auto; }
        pre code { background: none; color: inherit; }
        table { border-collapse: collapse; width: 100%; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 10px; text-align: left; }
        th { background: #3498db; color: white; }
        tr:nth-child(even) { background: #f9f9f9; }
        a { color: #3498db; }
        .nav { background: #2c3e50; padding: 10px; margin-bottom: 20px; border-radius: 5px; }
        .nav a { color: white; margin-right: 15px; text-decoration: none; }
        .highlight { background: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin: 20px 0; }
        .checklist { background: #f8f9fa; padding: 15px; border-radius: 5px; }
        .checklist li { margin: 8px 0; }
    </style>
</head>
<body>
    <div class="nav">
        <a href="INDEX.html">Index</a>
        <a href="CODE_ARCHITECTURE.html">Architecture</a>
        <a href="ERD_SCHEMA.html">Schema/ERD</a>
        <a href="VALIDATION_GUIDE.html">Validation</a>
        <a href="DEPLOYMENT_GUIDE.html">Deploy</a>
    </div>
<h1>ETL / Data Engineer Handoff</h1>

<h2>Overview</h2>

<p>You&#x27;re taking over the BenchSight ETL pipeline - a hockey analytics data warehouse that processes game tracking data into a 96-table dimensional model with 317+ statistical columns.</p>

<h2>Your Responsibilities</h2>

<p>1. <strong>ETL Pipeline Maintenance</strong> - Keep data flowing from tracking files to Supabase</p>
<p>2. <strong>Data Quality</strong> - Validate stats, fix anomalies, ensure accuracy</p>
<p>3. <strong>Schema Evolution</strong> - Add new tables/columns as needed</p>
<p>4. <strong>Performance</strong> - Optimize queries and data loading</p>

<hr>

<h2>Quick Start</h2>

<pre><code><h1>1. Test the pipeline works</h1>
<p>./run_etl.sh --status</p>

<h1>2. Process a game</h1>
<p>./run_etl.sh --game 18969</p>

<h1>3. Export to CSV</h1>
<p>./run_etl.sh --export</p>

<h1>4. Deploy to Supabase</h1>
<p>./run_deploy.sh</p>
</code></pre>

<hr>

<h2>Architecture</h2>

<h3>Data Flow</h3>
<pre><code>data/raw/games/{game_id}/BLB_*.xlsx   →   ETL Pipeline   →   data/output/*.csv   →   Supabase
<p>         ↓                                     ↓                    ↓</p>
<p>    Tracking files              Stage → Intermediate → Datamart    96 tables</p>
<p>    (events, shifts)            (raw)    (transforms)  (star schema)</p>
</code></pre>

<h3>Key Files</h3>

<table>
<tr><th>File</th><th>Purpose</th></tr>
<tr><td><hr><hr></td><td><hr><hr><hr></td></tr>
<tr><td><code>src/main.py</code></td><td>ETL entry point / CLI</td></tr>
<tr><td><code>src/pipeline/orchestrator.py</code></td><td>Coordinates ETL layers</td></tr>
<tr><td><code>src/ingestion/blb_loader.py</code></td><td>Loads BLB_Tables.xlsx</td></tr>
<tr><td><code>src/ingestion/game_loader.py</code></td><td>Loads game tracking files</td></tr>
<tr><td><code>src/ingestion/xy_loader.py</code></td><td>Loads XY coordinate data</td></tr>
<tr><td><code>scripts/flexible_loader.py</code></td><td>Supabase deployment</td></tr>
</table>

<h3>Database Layers</h3>

<table>
<tr><th>Layer</th><th>Purpose</th><th>Tables</th></tr>
<tr><td><hr><hr>-</td><td><hr><hr><hr></td><td><hr><hr>--</td></tr>
<tr><td>Stage</td><td>Raw data loading</td><td><code>stg_*</code></td></tr>
<tr><td>Intermediate</td><td>Transforms, joins</td><td><code>int_*</code></td></tr>
<tr><td>Datamart</td><td>Star schema (dims + facts)</td><td><code>dim_*</code>, <code>fact_*</code></td></tr>
</table>

<hr>

<h2>Core Tables</h2>

<h3>Dimensions (44 tables)</h3>
<p>Reference/lookup tables:</p>
<p>- <code>dim_player</code> - Player master data</p>
<p>- <code>dim_team</code> - Team definitions</p>
<p>- <code>dim_schedule</code> - Game schedule</p>
<p>- <code>dim_event_type</code> - Event type codes</p>
<p>- <code>dim_stat</code> - Stat definitions</p>

<h3>Facts (51 tables)</h3>
<p>Transactional/metric tables:</p>
<p>- <code>fact_events</code> - All tracked events (5,833 rows)</p>
<p>- <code>fact_shifts</code> - Player shifts (672 rows)</p>
<p>- <code>fact_player_game_stats</code> - <strong>317 columns per player per game</strong></p>
<p>- <code>fact_team_game_stats</code> - Team-level stats</p>
<p>- <code>fact_h2h</code> - Head-to-head matchups</p>
<p>- <code>fact_wowy</code> - With Or Without You analysis</p>
<p>- <code>fact_line_combos</code> - Line combination stats</p>

<hr>

<h2>Key ETL Rules</h2>

<h3>Event Attribution</h3>
<pre><code>event_player_1 = PRIMARY player (first row per event_index)
<p>event_player_2 = Secondary (assist 1, defender)</p>
<p>event_player_3 = Tertiary (assist 2)</p>
</code></pre>

<h3>Success Codes</h3>
<pre><code>&#x27;s&#x27; = successful
<p>&#x27;u&#x27; = unsuccessful</p>
</code></pre>

<h3>Goal Detection (CRITICAL)</h3>
<p>Goals are tracked TWO ways - must check BOTH:</p>
<pre><code>WHERE event_type = &#x27;Goal&#x27;
<p>   OR event_detail IN (&#x27;Shot Goal&#x27;, &#x27;Goal Scored&#x27;)</p>
</code></pre>

<hr>

<h2>Common Tasks</h2>

<h3>Add a New Game</h3>

<pre><code><h1>1. Place tracking file</h1>
<p>cp BLB_GameTracking_18999.xlsx data/raw/games/18999/</p>

<h1>2. Run ETL</h1>
<p>./run_etl.sh --game 18999</p>

<h1>3. Verify</h1>
<p>python scripts/validate_stats.py</p>

<h1>4. Deploy</h1>
<p>./run_deploy.sh --scope category --category all_facts --operation replace</p>
</code></pre>

<h3>Reprocess All Games</h3>

<pre><code>./run_etl.sh --process-all --export
<p>./run_deploy.sh</p>
</code></pre>

<h3>Add a New Stat Column</h3>

<p>1. Add to calculation in <code>src/analytics/</code></p>
<p>2. Update <code>docs/STATS_REFERENCE_COMPLETE.md</code></p>
<p>3. Add column to <code>sql/01_CREATE_ALL_TABLES.sql</code></p>
<p>4. Add test to <code>tests/test_stats_calculations.py</code></p>
<p>5. Run: <code>./run_etl.sh --export &amp;&amp; ./run_deploy.sh</code></p>

<h3>Fix Data Quality Issue</h3>

<pre><code><h1>1. Identify issue</h1>
<p>python scripts/qa_comprehensive.py</p>

<h1>2. Fix in source or transform</h1>
<h1>Edit relevant src/ file</h1>

<h1>3. Reprocess affected games</h1>
<p>./run_etl.sh --games 18969,18977 --export</p>

<h1>4. Validate</h1>
<p>python scripts/validate_stats.py</p>

<h1>5. Deploy</h1>
<p>./run_deploy.sh</p>
</code></pre>

<hr>

<h2>Utility Scripts</h2>

<p>Located in <code>scripts/utilities/</code>:</p>

<table>
<tr><th>Script</th><th>Purpose</th></tr>
<tr><td><hr><hr>--</td><td><hr><hr><hr></td></tr>
<tr><td><code>generate_schema.py</code></td><td>Generate SQL from CSV headers</td></tr>
<tr><td><code>schema_definition.py</code></td><td>Schema definitions</td></tr>
<tr><td><code>fix_data_accuracy.py</code></td><td>Fix data accuracy issues</td></tr>
<tr><td><code>fix_dim_mappings.py</code></td><td>Fix dimension mappings</td></tr>
<tr><td><code>populate_all_fks_v2.py</code></td><td>Populate foreign keys</td></tr>
<tr><td><code>add_all_fkeys.py</code></td><td>Add FK constraints</td></tr>
<tr><td><code>export_all_data.py</code></td><td>Export all data to CSV</td></tr>
<tr><td><code>validate_h2h_wowy.py</code></td><td>Validate H2H/WOWY tables</td></tr>
</table>

<hr>

<h2>Validation Scripts</h2>

<table>
<tr><th>Script</th><th>Purpose</th></tr>
<tr><td><hr><hr>--</td><td><hr><hr><hr></td></tr>
<tr><td><code>scripts/validate_stats.py</code></td><td>Validate stat calculations</td></tr>
<tr><td><code>scripts/validate_against_ground_truth.py</code></td><td>Compare to noradhockey.com</td></tr>
<tr><td><code>scripts/qa_comprehensive.py</code></td><td>Full QA sweep</td></tr>
<tr><td><code>scripts/qa_dynamic.py</code></td><td>Dynamic validation</td></tr>
<tr><td><code>scripts/etl_validation.py</code></td><td>Post-ETL checks</td></tr>
</table>

<hr>

<h2>SQL Files</h2>

<table>
<tr><th>File</th><th>Purpose</th></tr>
<tr><td><hr><hr></td><td><hr><hr><hr></td></tr>
<tr><td><code>sql/01_CREATE_ALL_TABLES.sql</code></td><td>Create all 96 tables</td></tr>
<tr><td><code>sql/02_TYPE_FIXES.sql</code></td><td>Fix column types</td></tr>
<tr><td><code>sql/03_TRUNCATE_DATA.sql</code></td><td>Truncate all data</td></tr>
<tr><td><code>sql/utilities/drop_all_tables.sql</code></td><td>Drop all tables</td></tr>
<tr><td><code>sql/utilities/reset_supabase.sql</code></td><td>Full reset</td></tr>
</table>

<hr>

<h2>Configuration</h2>

<h3>config/config_local.ini</h3>
<pre><code>[supabase]
<p>url = https://YOUR_PROJECT.supabase.co</p>
<p>service_key = YOUR_SERVICE_ROLE_KEY</p>

<p>[loader]</p>
<p>batch_size = 500</p>
<p>verbose = true</p>
</code></pre>

<h3>Environment Setup</h3>
<pre><code>pip install pandas supabase openpyxl python-dotenv
</code></pre>

<hr>

<h2>Known Issues</h2>

<p>See <code>docs/HONEST_ASSESSMENT.md</code> for full list:</p>

<p>1. <strong>Shift data gaps</strong> - Some games have incomplete shift tracking</p>
<p>2. <strong>XY coordinate gaps</strong> - Not all events have coordinates</p>
<p>3. <strong>Period codes</strong> - Some period fields have &quot;OT&quot;, &quot;SO&quot; (text, not int)</p>
<p>4. <strong>Player numbers</strong> - Some have &quot;FA&quot; for free agent</p>

<hr>

<h2>Performance Tips</h2>

<p>1. <strong>Batch inserts</strong> - Use <code>batch_size=500</code> for Supabase</p>
<p>2. <strong>Replace vs Append</strong> - Use <code>replace</code> for clean loads, <code>append</code> for incremental</p>
<p>3. <strong>Category loading</strong> - Load dims first, then facts</p>
<p>4. <strong>Parallel processing</strong> - Games can be processed in parallel</p>

<hr>

<h2>Monitoring</h2>

<h3>Check Table Counts</h3>
<pre><code>python scripts/flexible_loader.py --scope full --dry-run
</code></pre>

<h3>Check Data Quality</h3>
<pre><code>python scripts/qa_comprehensive.py
</code></pre>

<h3>Verify Goals Match Official</h3>
<pre><code>python scripts/validate_against_ground_truth.py
</code></pre>

<hr>

<h2>Contacts &amp; Resources</h2>

<p>- <strong>Data Source</strong>: NORAD Hockey League (noradhockey.com)</p>
<p>- <strong>Ground Truth</strong>: Official game box scores</p>
<p>- <strong>Documentation</strong>: <code>docs/INDEX.md</code></p>
<p>- <strong>Stats Reference</strong>: <code>docs/STATS_REFERENCE_COMPLETE.md</code></p>

<hr>

<h2>First Week Checklist</h2>

<p>- [ ] Run <code>./run_etl.sh --status</code> to verify pipeline works</p>
<p>- [ ] Review <code>docs/CODE_ARCHITECTURE.md</code> for code structure</p>
<p>- [ ] Review <code>docs/STATS_REFERENCE_COMPLETE.md</code> for all stats</p>
<p>- [ ] Run full test suite: <code>pytest tests/ -v</code></p>
<p>- [ ] Deploy test: <code>./run_deploy.sh --dry-run</code></p>
<p>- [ ] Review <code>docs/HONEST_ASSESSMENT.md</code> for known issues</p>
<p>- [ ] Process one game end-to-end</p>
<p>- [ ] Validate against noradhockey.com</p>

</body></html>
