# ETL Pipeline Reality Check

## What the ETL Pipeline Actually Produces

When you run `python -m src.pipeline.orchestrator` or similar, the ETL creates **13 tables**:

| Table | Rows | Source |
|-------|------|--------|
| dim_event_type | 7 | Static definition |
| dim_period | 5 | Static definition |
| dim_player | 337 | BLB_Tables.xlsx |
| dim_position | 8 | Static definition |
| dim_schedule | 562 | BLB_Tables.xlsx |
| dim_skill_tier | 5 | Static definition |
| dim_strength | 9 | Static definition |
| dim_team | 26 | BLB_Tables.xlsx |
| dim_venue | 2 | Static definition |
| dim_zone | 3 | Static definition |
| fact_box_score | ~119 | Calculated from events |
| fact_events | ~11,181 | Game tracking files |
| fact_gameroster | 14,473 | BLB_Tables.xlsx |

## What's in data/output/ (111 tables)

The output folder contains **111 tables** that were created through a combination of:

1. **ETL Pipeline (13 tables)** - Generated automatically from source data
2. **Manual/Script Generation (~98 tables)** - Created through separate processes

### Tables NOT Generated by ETL

These tables exist in output/ but are **NOT** regenerated by running the ETL:

- All `fact_player_*` advanced stats tables
- All `fact_wowy`, `fact_h2h`, `fact_line_combos` analytics
- All `fact_shifts_*` detailed shift tables  
- All micro-stat and zone tables
- Most dimension lookup tables (dim_stat, dim_play_detail, etc.)
- QA validation tables

## Important Warning

**DO NOT** run the ETL pipeline expecting it to regenerate all 111 tables.

If you run:
```bash
python -c "from src.pipeline.orchestrator import PipelineOrchestrator; PipelineOrchestrator().run_full_pipeline(export_csv=True)"
```

It will **OVERWRITE** the 13 tables it knows how to generate, but leave the other 98 intact.

## Supabase Deployment

The deploy script works correctly with all 111 CSVs:

```bash
python scripts/deploy_supabase.py --test
python scripts/deploy_supabase.py --all
```

## To Preserve Data Integrity

1. **Backup before running ETL**: `cp -r data/output data/output_backup`
2. **Only deploy existing CSVs**: Don't regenerate unless you know what you're doing
3. **The 111 CSVs in output/ are the source of truth** for Supabase deployment
