BENCHSIGHT + LLMS – HOW TO TALK TO DIFFERENT MODELS
===================================================

1) When you talk to *any* LLM about this project, include:
   - A short description of the project’s purpose.
   - The stat catalog (or at least the subset relevant for the question).
   - The current table schema (column names, fact/dim tables).

2) Some prompts you can use:
   - SQL generation:
     """
     Here is my fact_events_long table schema [...].
     Here is my BenchSight stats catalog [...].
     Please write SQL for Postgres that computes EV_CORSI_FOR per player per game.
     """

   - DAX / Power BI measures:
     """
     Here is a description of my Power BI model tables [...].
     Using this model, write DAX measures for:
         EV_SHOTS_FOR, EV_CORSI_FOR, EV_FENWICK_FOR, XG_FOR.
     Use filter context that matches the definitions in this stats catalog [...].
     """

   - ML / modeling help:
     """
     I have event-level hockey data with the following fields [...].
     I want to build an xG model using gradient boosting. Propose:
         * feature set
         * train/validation split
         * evaluation metrics
     """

3) For long multi-LLM collaborations:
   - Keep a stable **requirements document** (like this one) in your repo.
   - Ask each model to read the requirements first before suggesting changes.
   - Explicitly ask LLMs not to violate or rename core concepts (e.g., linked_event_id,
     sequence_index, play_index) unless you want to change the design.
