<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DATA VALIDATION GUIDE</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #34495e; margin-top: 30px; }
        h3 { color: #7f8c8d; }
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Consolas', monospace;
        }
        pre {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        pre code {
            background: none;
            color: inherit;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th { background: #3498db; color: white; }
        tr:nth-child(even) { background: #f9f9f9; }
        a { color: #3498db; }
        hr { border: none; border-top: 1px solid #ddd; margin: 30px 0; }
        .success { color: #27ae60; }
        .warning { color: #f39c12; }
        .error { color: #e74c3c; }
    </style>
</head>
<body>
<h1>Data Validation & Verification Guide</h1>
<strong>Version:</strong> 1.0  
<strong>Date:</strong> December 30, 2025
<hr>
<h2>How to Verify Supabase Loaded 100% Accurately</h2>
<h3>Quick Verification Checklist</h3>
<pre><code>□ 1. Row counts match CSV files
□ 2. All 96 tables exist
□ 3. No loading errors in logs
□ 4. Sample data spot checks pass
□ 5. Goals match noradhockey.com
□ 6. Referential integrity tests pass
□ 7. Primary key uniqueness verified</code></pre>
<hr>
<h2>Step 1: Verify Row Counts</h2>
<h3>Run This SQL in Supabase</h3>
<pre><code>-- Get row counts for all tables
SELECT 
    schemaname,
    relname as table_name,
    n_live_tup as row_count
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY relname;</code></pre>
<h3>Compare to Expected Counts</h3>
<td> Table </td> Expected Rows <td> Check </td>
<td>-------</td>---------------<td>-------</td>
<td> dim_player </td> 337 <td> □ </td>
<td> dim_team </td> 26 <td> □ </td>
<td> dim_schedule </td> 562 <td> □ </td>
<td> fact_events </td> 5,833 <td> □ </td>
<td> fact_events_player </td> 11,635 <td> □ </td>
<td> fact_shifts </td> 672 <td> □ </td>
<td> fact_shifts_player </td> 4,626 <td> □ </td>
<td> fact_player_game_stats </td> 107 <td> □ </td>
<td> fact_team_game_stats </td> 8 <td> □ </td>
<td> fact_h2h </td> 684 <td> □ </td>
<td> fact_wowy </td> 641 <td> □ </td>
<td> fact_line_combos </td> 332 <td> □ </td>
<td> fact_player_boxscore_all </td> 14,473 <td> □ </td>
<td> fact_gameroster </td> 14,471 <td> □ </td>
<h3>Automated Row Count Check (Python)</h3>
<pre><code>import pandas as pd
from supabase import create_client
<h1>Load expected counts from CSVs</h1>
expected = {}
for csv_file in Path('data/output').glob('<em>.csv'):
    table = csv_file.stem
    df = pd.read_csv(csv_file)
    expected[table] = len(df)
<h1>Get actual counts from Supabase</h1>
actual = {}
for table in expected.keys():
    response = supabase.table(table).select('</em>', count='exact').execute()
    actual[table] = response.count
<h1>Compare</h1>
mismatches = []
for table in expected:
    if expected[table] != actual.get(table, 0):
        mismatches.append({
            'table': table,
            'expected': expected[table],
            'actual': actual.get(table, 0),
            'diff': expected[table] - actual.get(table, 0)
        })
<p>if mismatches:
    print("⚠️ MISMATCHES FOUND:")
    for m in mismatches:
        print(f"  {m['table']}: expected {m['expected']}, got {m['actual']}")
else:
    print("✅ All row counts match!")</code></pre></p>
<hr>
<h2>Step 2: Verify All Tables Exist</h2>
<h3>SQL Check</h3>
<pre><code>-- Count tables (should be 96 + logging tables)
SELECT COUNT(<em>) as table_count
FROM information_schema.tables 
WHERE table_schema = 'public' 
  AND table_type = 'BASE TABLE';
<p>-- List all tables
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public'
ORDER BY table_name;</code></pre></p>
<h3>Expected: 96 data tables + 5 logging tables = 101+ tables</h3>
<hr>
<h2>Step 3: Check Loading Logs</h2>
<h3>File Logs</h3>
<pre><code><h1>Check latest log file</h1>
cat logs/$(ls -t logs/ <td> head -1)/run.log </td> grep -E "ERROR<td>FAILED</td>SUCCESS"
<h1>Count errors</h1>
grep -c "ERROR" logs/</em>/run.log</code></pre>
<h3>Supabase Logs (if logging enabled)</h3>
<pre><code>-- Check recent ETL runs
SELECT <em> FROM log_etl_runs 
ORDER BY started_at DESC 
LIMIT 5;
<p>-- Check for failed tables
SELECT </em> FROM log_etl_tables 
WHERE status = 'failed'
ORDER BY created_at DESC;</p>
<p>-- Check errors
SELECT <em> FROM log_errors 
WHERE resolved = false;</code></pre></p>
<hr>
<h2>Step 4: Sample Data Spot Checks</h2>
<h3>Check Primary Keys Are Unique</h3>
<pre><code>-- Events should have unique keys
SELECT event_key, COUNT(</em>) 
FROM fact_events 
GROUP BY event_key 
HAVING COUNT(<em>) > 1;
-- Should return 0 rows (except known duplicate EV1896901594)
<p>-- Shifts should have unique keys
SELECT shift_key, COUNT(</em>) 
FROM fact_shifts 
GROUP BY shift_key 
HAVING COUNT(<em>) > 1;
-- Should return 0 rows</p>
<p>-- Players should have unique IDs
SELECT player_id, COUNT(</em>) 
FROM dim_player 
GROUP BY player_id 
HAVING COUNT(<em>) > 1;
-- Should return 0 rows</code></pre></p>
<h3>Check Sample Values Match CSV</h3>
<pre><code>-- Compare a specific player
SELECT </em> FROM dim_player WHERE player_id = 'P100023';
<p>-- Compare a specific event
SELECT <em> FROM fact_events WHERE event_key = 'EV1896900001';</p>
<p>-- Compare a specific shift
SELECT </em> FROM fact_shifts WHERE shift_key = '18969_1';</code></pre></p>
<hr>
<h2>Step 5: Validate Against Official Stats (noradhockey.com)</h2>
<h3>Goals Validation</h3>
<pre><code>-- Get goals per team per game
SELECT 
    game_id,
    CASE WHEN team_venue = 'Home' THEN 'Home' ELSE 'Away' END as venue,
    COUNT(<em>) as goals
FROM fact_events
WHERE event_type = 'Goal'
GROUP BY game_id, team_venue
ORDER BY game_id;</code></pre>
<h3>Compare to Official</h3>
<td> Game </td> Official Home <td> Calculated Home </td> Official Away <td> Calculated Away </td> Match <td>
</td>------<td>---------------</td>-----------------<td>---------------</td>-----------------<td>-------</td>
<td> 18969 </td> ? <td> ? </td> ? <td> ? </td> □ <td>
</td> 18977 <td> ? </td> ? <td> ? </td> ? <td> □ </td>
<td> 18981 </td> ? <td> ? </td> ? <td> ? </td> □ <td>
</td> 18987 <td> ? </td> ? <td> ? </td> ? <td> □ </td>
<h3>Player Points Validation</h3>
<pre><code>-- Top scorers for a game
SELECT 
    player_name,
    goals,
    assists,
    points
FROM fact_player_game_stats
WHERE game_id = '18969'
ORDER BY points DESC
LIMIT 10;</code></pre>
<hr>
<h2>Step 6: Referential Integrity Tests</h2>
<h3>Run the Test Suite</h3>
<pre><code><h1>Run all integrity tests</h1>
python -m pytest tests/test_fk_relationships.py -v
<h1>Run comprehensive integrity</h1>
python -m pytest tests/test_comprehensive_integrity.py -v</code></pre>
<h3>Manual FK Checks</h3>
<pre><code>-- Events should reference valid shifts
SELECT COUNT(</em>) as orphan_events
FROM fact_events e
LEFT JOIN fact_shifts s ON e.shift_key = s.shift_key
WHERE s.shift_key IS NULL 
  AND e.shift_key IS NOT NULL
  AND e.shift_key NOT LIKE '%nan%';
-- Acceptable: 0 or small number
<p>-- Event players should reference valid events
SELECT COUNT(<em>) as orphan_event_players
FROM fact_events_player ep
LEFT JOIN fact_events e ON ep.event_key = e.event_key
WHERE e.event_key IS NULL;
-- Should be 0</p>
<p>-- Players should exist in dim_player
SELECT COUNT(</em>) as orphan_players
FROM fact_player_game_stats pgs
LEFT JOIN dim_player p ON pgs.player_id = p.player_id
WHERE p.player_id IS NULL;
-- Should be 0</code></pre></p>
<hr>
<h2>Step 7: Data Quality Checks</h2>
<h3>Check for NULL Values in Required Fields</h3>
<pre><code>-- Events without type
SELECT COUNT(<em>) FROM fact_events WHERE event_type IS NULL;
<p>-- Shifts without game
SELECT COUNT(</em>) FROM fact_shifts WHERE game_id IS NULL;</p>
<p>-- Players without name
SELECT COUNT(<em>) FROM dim_player WHERE player_full_name IS NULL;</code></pre></p>
<h3>Check for Invalid Values</h3>
<pre><code>-- Events with invalid period
SELECT COUNT(</em>) FROM fact_events 
WHERE period NOT IN (1, 2, 3, 4, 5) AND period IS NOT NULL;
<p>-- Negative durations
SELECT COUNT(<em>) FROM fact_shifts WHERE shift_duration < 0;</p>
<p>-- Invalid percentages
SELECT COUNT(</em>) FROM fact_wowy WHERE cf_pct_together > 100 OR cf_pct_together < 0;</code></pre></p>
<hr>
<h2>Known Data Issues (Expected)</h2>
<p>These are documented issues that are acceptable:</p>
<td> Issue </td> Count <td> Impact </td> Notes <td>
</td>-------<td>-------</td>--------<td>-------</td>
<td> Events without shift match </td> 58 <td> Minor </td> shift_key contains 'nan' <td>
</td> Events with NULL period <td> 2 </td> Minor <td> Filter in queries </td>
<td> Shifts without player attribution </td> 283 <td> Minor </td> Some games shift-only <td>
</td> Duplicate event_key <td> 1 </td> Minor <td> EV1896901594, use UPSERT </td>
<hr>
<h2>Automated Validation Script</h2>
<pre><code>#!/usr/bin/env python3
"""
Comprehensive data validation for Supabase
Run after every load to verify accuracy
"""
<p>import pandas as pd
from pathlib import Path
from supabase import create_client
import json</p>
<p>def validate_all():
    results = {
        'row_counts': validate_row_counts(),
        'primary_keys': validate_primary_keys(),
        'foreign_keys': validate_foreign_keys(),
        'data_quality': validate_data_quality(),
        'business_rules': validate_business_rules()
    }
    
    # Summary
    total_checks = sum(r['total'] for r in results.values())
    passed_checks = sum(r['passed'] for r in results.values())
    
    print(f"\n{'='<em>50}")
    print(f"VALIDATION SUMMARY")
    print(f"{'='</em>50}")
    print(f"Total Checks: {total_checks}")
    print(f"Passed: {passed_checks}")
    print(f"Failed: {total_checks - passed_checks}")
    print(f"Pass Rate: {passed_checks/total_checks<em>100:.1f}%")
    
    if passed_checks == total_checks:
        print("\n✅ ALL VALIDATIONS PASSED!")
    else:
        print("\n⚠️ SOME VALIDATIONS FAILED - Review above")
    
    return results</p>
<p>def validate_row_counts():
    """Compare CSV row counts to Supabase"""
    print("\n--- Row Count Validation ---")
    passed = 0
    failed = 0
    
    for csv_file in Path('data/output').glob('</em>.csv'):
        table = csv_file.stem
        expected = len(pd.read_csv(csv_file))
        
        try:
            response = supabase.table(table).select('*', count='exact').limit(1).execute()
            actual = response.count
        except:
            actual = 0
        
        if expected == actual:
            print(f"  ✓ {table}: {actual} rows")
            passed += 1
        else:
            print(f"  ✗ {table}: expected {expected}, got {actual}")
            failed += 1
    
    return {'total': passed + failed, 'passed': passed}</p>
<p>def validate_primary_keys():
    """Check primary key uniqueness"""
    print("\n--- Primary Key Validation ---")
    checks = [
        ('fact_events', 'event_key'),
        ('fact_shifts', 'shift_key'),
        ('dim_player', 'player_id'),
        ('dim_team', 'team_id'),
    ]
    
    passed = 0
    for table, pk in checks:
        # Check for duplicates
        response = supabase.rpc('check_duplicates', {
            'table_name': table, 
            'column_name': pk
        }).execute()
        
        if response.data == 0:
            print(f"  ✓ {table}.{pk} is unique")
            passed += 1
        else:
            print(f"  ✗ {table}.{pk} has {response.data} duplicates")
    
    return {'total': len(checks), 'passed': passed}</p>
<p>if __name__ == '__main__':
    validate_all()</code></pre></p>
<hr>
<h2>Verification Checklist Summary</h2>
<h3>Before Go-Live</h3>
<pre><code>LOAD VERIFICATION
□ All 96 tables created
□ Row counts match 100%
□ No ERROR entries in logs
□ Primary keys unique
□ Foreign keys valid (>95%)
<p>DATA ACCURACY  
□ Goals match noradhockey.com
□ Player points match
□ Team stats match
□ Sample spot checks pass</p>
<p>DATA QUALITY
□ No unexpected NULLs
□ No invalid values
□ No orphan records
□ Test suite passes (326 tests)</p>
<p>SIGN-OFF
□ Verified by: _____________
□ Date: _____________
□ Version: _____________</code></pre></p>
<hr>
<h2>Troubleshooting Load Issues</h2>
<h3>Issue: Row count mismatch</h3>
<strong>Cause:</strong> Duplicate key caused skip
<strong>Fix:</strong> 
<pre><code>python scripts/load_all_tables.py --table TABLE_NAME --upsert</code></pre>
<h3>Issue: Table missing</h3>
<strong>Cause:</strong> Schema not deployed
<strong>Fix:</strong> Run <code>sql/05_FINAL_COMPLETE_SCHEMA.sql</code> in Supabase
<h3>Issue: Foreign key violation</h3>
<strong>Cause:</strong> Dimension not loaded before fact
<strong>Fix:</strong> Load dimensions first, then facts
<h3>Issue: Connection timeout</h3>
<strong>Cause:</strong> Large batch size or slow network
<strong>Fix:</strong> Reduce batch size in config
<pre><code>[loader]
batch_size = 100  # Reduce from 500</code></pre>

</body>
</html>