<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DATA LOADER GUIDE</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #34495e; margin-top: 30px; }
        h3 { color: #7f8c8d; }
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Consolas', monospace;
        }
        pre {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        pre code {
            background: none;
            color: inherit;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th { background: #3498db; color: white; }
        tr:nth-child(even) { background: #f9f9f9; }
        a { color: #3498db; }
        hr { border: none; border-top: 1px solid #ddd; margin: 30px 0; }
        .success { color: #27ae60; }
        .warning { color: #f39c12; }
        .error { color: #e74c3c; }
    </style>
</head>
<body>
<h1>Data Loader Complete Guide</h1>
<strong>Version:</strong> 2.0  
<strong>Date:</strong> December 30, 2025
<hr>
<h2>Overview</h2>
<p>BenchSight has two loader scripts:
1. <strong><code>load_all_tables.py</code></strong> - Simple loader for all 96 tables
2. <strong><code>flexible_loader_with_logging.py</code></strong> - Full-featured loader with logging</p>
<hr>
<h2>Quick Reference</h2>
<pre><code><h1>Load everything</h1>
python scripts/load_all_tables.py --upsert
<h1>Preview only (no changes)</h1>
python scripts/load_all_tables.py --dry-run
<h1>Load single table</h1>
python scripts/load_all_tables.py --table dim_player --upsert
<h1>Full logging version</h1>
python scripts/flexible_loader_with_logging.py --scope full --operation replace</code></pre>
<hr>
<h2>Script 1: load_all_tables.py</h2>
<h3>Purpose</h3>
Loads all CSV files from <code>data/output/</code> to Supabase.
<h3>Commands</h3>
<td> Command </td> Description <td>
</td>---------<td>-------------</td>
<td> <code>--upsert</code> </td> Insert new rows, update existing (handles duplicates) <td>
</td> <code>--dry-run</code> <td> Preview what would be loaded, no changes </td>
<td> <code>--table TABLE</code> </td> Load only specified table <td>
</td> <code>--skip-dims</code> <td> Skip dimension tables, load only facts </td>
<h3>Examples</h3>
<pre><code><h1>Load all tables with upsert (recommended)</h1>
python scripts/load_all_tables.py --upsert
<h1>Preview what will load</h1>
python scripts/load_all_tables.py --dry-run
<h1>Load single table</h1>
python scripts/load_all_tables.py --table fact_events --upsert
<h1>Load only fact tables</h1>
python scripts/load_all_tables.py --skip-dims --upsert</code></pre>
<h3>Output</h3>
<pre><code>Connecting to Supabase...
<p>============================================================
LOADING 96 TABLES (upsert)
============================================================</p>
<p>[ 1/96] dim_comparison_type... ✓ 5 rows
[ 2/96] dim_composite_rating... ✓ 6 rows
[ 3/96] dim_danger_zone... ✓ 5 rows
...
[96/96] qa_suspicious_stats... ✓ 22 rows</p>
<p>============================================================
COMPLETE
============================================================
Tables: 96/96
Total Rows: 120,534
Duration: 45.2s</code></pre></p>
<hr>
<h2>Script 2: flexible_loader_with_logging.py</h2>
<h3>Purpose</h3>
Full-featured loader with comprehensive logging and more options.
<h3>Commands</h3>
<td> Command </td> Description <td>
</td>---------<td>-------------</td>
<td> <code>--scope full</code> </td> Load all tables <td>
</td> <code>--scope table --table NAME</code> <td> Load single table </td>
<td> <code>--operation replace</code> </td> Delete existing, insert new <td>
</td> <code>--operation upsert</code> <td> Insert/update (handles duplicates) </td>
<td> <code>--operation append</code> </td> Add without deleting <td>
</td> <code>--dry-run</code> <td> Preview only </td>
<td> <code>--log-to-supabase</code> </td> Write logs to Supabase tables <td>
</td> <code>--show-config</code> <td> Display current configuration </td>
<td> <code>--test-connection</code> </td> Test Supabase connection <td>
</td> <code>--show-last-run</code> <td> Show last run results </td>
<h3>Examples</h3>
<pre><code><h1>Show configuration</h1>
python scripts/flexible_loader_with_logging.py --show-config
<h1>Test connection</h1>
python scripts/flexible_loader_with_logging.py --test-connection
<h1>Full replace (delete + insert)</h1>
python scripts/flexible_loader_with_logging.py --scope full --operation replace
<h1>Full upsert (safer)</h1>
python scripts/flexible_loader_with_logging.py --scope full --operation upsert
<h1>Single table upsert</h1>
python scripts/flexible_loader_with_logging.py --scope table --table fact_events --operation upsert
<h1>Dry run</h1>
python scripts/flexible_loader_with_logging.py --scope full --operation replace --dry-run
<h1>With Supabase logging</h1>
python scripts/flexible_loader_with_logging.py --scope full --operation replace --log-to-supabase
<h1>View last run</h1>
python scripts/flexible_loader_with_logging.py --show-last-run</code></pre>
<h3>Log Output</h3>
<p>Logs are written to <code>logs/YYYY-MM-DD/run_id/</code>:
<ul>
<li><code>run.log</code> - Human-readable log</li>
<li><code>run.jsonl</code> - JSON lines for parsing</li>
<li><code>summary.json</code> - Run summary</li>
<li><code>SUMMARY.md</code> - Markdown summary</li>
<li><code>errors/errors.log</code> - Error details</li>
<li><code>tables/<em>.json</code> - Per-table results</li>
</ul></p>
<hr>
<h2>Operations Explained</h2>
<h3>REPLACE</h3>
<pre><code>1. Delete all existing rows from table
2. Insert all rows from CSV</code></pre>
<strong>Use when:</strong> Fresh load, schema changed, data corruption
<h3>UPSERT</h3>
<pre><code>1. For each row:
<ul>
<li>If primary key exists: UPDATE</li>
<li>If primary key doesn't exist: INSERT</code></pre></li>
</ul>
<strong>Use when:</strong> Incremental updates, handling duplicates
<h3>APPEND</h3>
<pre><code>1. Insert all rows (may fail on duplicates)</code></pre>
<strong>Use when:</strong> Adding new data only, keys guaranteed unique
<hr>
<h2>Loading Specific Data</h2>
<h3>Load One Game's Data</h3>
<pre><code><h1>After running ETL for a specific game, load all related tables</h1>
<h1>Tables that contain game_id will have data for that game</h1>
<h1>Upsert all tables (safest)</h1>
python scripts/load_all_tables.py --upsert
<h1>Or load specific tables</h1>
python scripts/load_all_tables.py --table fact_events --upsert
python scripts/load_all_tables.py --table fact_shifts --upsert
python scripts/load_all_tables.py --table fact_events_player --upsert</code></pre>
<h3>Load Only Dimension Tables</h3>
<pre><code><h1>Load dims first (they're referenced by facts)</h1>
for table in dim_player dim_team dim_schedule dim_event_type dim_period; do
    python scripts/load_all_tables.py --table $table --upsert
done</code></pre>
<h3>Load Only Fact Tables</h3>
<pre><code>python scripts/load_all_tables.py --skip-dims --upsert</code></pre>
<hr>
<h2>Editing Dimension Tables</h2>
<h3>Option 1: Edit CSV and Reload</h3>
<pre><code><h1>1. Edit the CSV file</h1>
nano data/output/dim_event_type.csv
<h1>2. Reload the table</h1>
python scripts/load_all_tables.py --table dim_event_type --upsert</code></pre>
<h3>Option 2: Edit in Supabase Directly</h3>
<p>1. Go to https://supabase.com/dashboard/project/uuaowslhpgyiudmbvqze
2. Navigate to Table Editor
3. Find dimension table
4. Edit rows directly
5. Changes are immediate</p>
<h3>Option 3: SQL Update</h3>
<pre><code>-- In Supabase SQL Editor
UPDATE dim_event_type 
SET event_type = 'Wrist Shot'
WHERE event_type_id = 'EVT001';
<p>-- Add new row
INSERT INTO dim_event_type (event_type_id, event_type)
VALUES ('EVT999', 'New Event Type');</p>
<p>-- Delete row
DELETE FROM dim_event_type 
WHERE event_type_id = 'EVT999';</code></pre></p>
<hr>
<h2>Troubleshooting</h2>
<h3>"Could not find column X"</h3>
<strong>Cause:</strong> Schema in Supabase doesn't match CSV columns
<strong>Fix:</strong>
<pre><code><h1>1. Regenerate schema from CSV</h1>
<h1>2. Run new schema SQL in Supabase</h1>
<h1>3. Reload data</h1></code></pre>
<h3>"Duplicate key violation"</h3>
<strong>Cause:</strong> Primary key already exists
<strong>Fix:</strong>
<pre><code><h1>Use upsert instead of replace/append</h1>
python scripts/load_all_tables.py --upsert</code></pre>
<h3>"Foreign key violation"</h3>
<strong>Cause:</strong> Referenced row doesn't exist in parent table
<strong>Fix:</strong>
<pre><code><h1>Load dimension tables first</h1>
python scripts/load_all_tables.py --table dim_player --upsert
python scripts/load_all_tables.py --table dim_team --upsert
<h1>Then load fact tables</h1>
python scripts/load_all_tables.py --skip-dims --upsert</code></pre>
<h3>Connection Error</h3>
<strong>Cause:</strong> Invalid credentials or network issue
<strong>Fix:</strong>
<pre><code><h1>Check config</h1>
python scripts/flexible_loader_with_logging.py --show-config
<h1>Test connection</h1>
python scripts/flexible_loader_with_logging.py --test-connection</code></pre>
<hr>
<h2>Configuration</h2>
<h3>Config File Location</h3>
<pre><code>config/config_local.ini</code></pre>
<h3>Config Contents</h3>
<pre><code>[supabase]
url = https://YOUR_PROJECT.supabase.co
service_key = YOUR_SERVICE_ROLE_KEY
<p>[loader]
batch_size = 500
verbose = true
default_operation = upsert</p>
<p>[paths]
data_dir = data/output
log_dir = logs</code></pre></p>
<h3>Environment Variable Alternative</h3>
<pre><code>export SUPABASE_URL="https://YOUR_PROJECT.supabase.co"
export SUPABASE_SERVICE_KEY="YOUR_KEY"</code></pre>
<hr>
<h2>Batch Size Tuning</h2>
<p>Default batch size is 500 rows per API call. Adjust if needed:</p>
<pre><code><h1>In config_local.ini</h1>
[loader]
batch_size = 1000  # Faster but may hit limits
batch_size = 100   # Slower but more reliable</code></pre>
<hr>
<h2>Full Reload Process</h2>
<p>To completely reload all data:</p>
<pre><code><h1>1. Run truncate SQL in Supabase</h1>
<h1>(Use sql/06_TRUNCATE_ALL_DATA.sql)</h1>
<h1>2. Load all tables</h1>
python scripts/load_all_tables.py --upsert
<h1>3. Verify</h1>
python scripts/flexible_loader_with_logging.py --show-last-run</code></pre>
<hr>
<h2>Automation</h2>
<h3>Cron Job Example</h3>
<pre><code><h1>Run nightly at 2 AM</h1>
0 2 </em> <em> </em> cd /path/to/benchsight && python scripts/load_all_tables.py --upsert >> logs/cron.log 2>&1</code></pre>
<h3>Python Script</h3>
<pre><code>import subprocess
import datetime
<p>def run_loader():
    result = subprocess.run(
        ["python", "scripts/load_all_tables.py", "--upsert"],
        capture_output=True,
        text=True
    )
    print(f"[{datetime.now()}] Loader completed")
    print(result.stdout)
    if result.returncode != 0:
        print(f"ERRORS: {result.stderr}")</p>
<p>if __name__ == "__main__":
    run_loader()</code></pre></p>
<hr>
<h2>Load Order</h2>
<p>Tables are loaded in dependency order:</p>
<p>1. <strong>Dimension Tables (44)</strong> - No dependencies
<ul>
<li>dim_player, dim_team, dim_schedule, etc.</li>
</ul></p>
<p>2. <strong>Fact Tables (51)</strong> - Depend on dimensions
<ul>
<li>fact_events, fact_shifts, etc.</li>
</ul></p>
<p>3. <strong>Other Tables (1)</strong>
<ul>
<li>qa_suspicious_stats</li>
</ul></p>
<p>The scripts handle this order automatically.</p>
<hr>
<h2>Monitoring Loads</h2>
<h3>Check Table Counts</h3>
<pre><code>-- In Supabase SQL Editor
SELECT <em> FROM get_all_table_counts();</code></pre>
<h3>Check Recent Runs</h3>
<pre><code>SELECT </em> FROM v_recent_runs;</code></pre>
<h3>Check Specific Table</h3>
<pre><code>SELECT COUNT(<em>) FROM fact_events;
SELECT </em> FROM fact_events LIMIT 10;</code></pre>
<hr>
<h2>CSV File Requirements</h2>
<p>For the loader to work, CSV files must:</p>
<p>1. Be in <code>data/output/</code> directory
2. Have filename matching table name (e.g., <code>dim_player.csv</code> → <code>dim_player</code>)
3. Have header row with column names
4. Have column names matching Supabase schema
5. Use UTF-8 encoding</p>
<hr>
<h2>Summary</h2>
<td> Task </td> Command <td>
</td>------<td>---------</td>
<td> Load all, handle duplicates </td> <code>python scripts/load_all_tables.py --upsert</code> <td>
</td> Preview only <td> <code>python scripts/load_all_tables.py --dry-run</code> </td>
<td> Load single table </td> <code>python scripts/load_all_tables.py --table NAME --upsert</code> <td>
</td> Full replace with logging <td> <code>python scripts/flexible_loader_with_logging.py --scope full --operation replace</code> </td>
<td> Check config </td> <code>python scripts/flexible_loader_with_logging.py --show-config</code> <td>
</td> Test connection <td> <code>python scripts/flexible_loader_with_logging.py --test-connection</code> </td>

</body>
</html>