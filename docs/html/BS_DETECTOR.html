<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BS Detector - BenchSight</title>
    <style>
        :root {
            --bg-dark: #1a1a2e;
            --bg-card: #16213e;
            --accent: #e94560;
            --accent-green: #00ff88;
            --accent-yellow: #ffd700;
            --text: #eee;
            --text-dim: #888;
            --border: #333;
        }
        
        * { box-sizing: border-box; margin: 0; padding: 0; }
        
        body {
            font-family: 'Segoe UI', system-ui, sans-serif;
            background: var(--bg-dark);
            color: var(--text);
            line-height: 1.6;
            padding: 20px;
        }
        
        .container { max-width: 1200px; margin: 0 auto; }
        
        h1 {
            color: var(--accent);
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-align: center;
        }
        
        .subtitle {
            text-align: center;
            color: var(--text-dim);
            margin-bottom: 30px;
        }
        
        h2 {
            color: var(--accent-green);
            margin: 30px 0 15px 0;
            padding-bottom: 5px;
            border-bottom: 2px solid var(--accent-green);
        }
        
        h3 {
            color: var(--accent-yellow);
            margin: 20px 0 10px 0;
        }
        
        .card {
            background: var(--bg-card);
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            border-left: 4px solid var(--accent);
        }
        
        .card.green { border-left-color: var(--accent-green); }
        .card.yellow { border-left-color: var(--accent-yellow); }
        .card.red { border-left-color: var(--accent); }
        
        pre, code {
            font-family: 'Consolas', 'Monaco', monospace;
            background: #0f0f1a;
            border-radius: 5px;
        }
        
        pre {
            padding: 15px;
            overflow-x: auto;
            margin: 10px 0;
        }
        
        code { padding: 2px 6px; }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }
        
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }
        
        th {
            background: var(--bg-card);
            color: var(--accent-green);
        }
        
        tr:hover { background: rgba(255,255,255,0.05); }
        
        .highlight { color: var(--accent-green); font-weight: bold; }
        .warning { color: var(--accent-yellow); }
        .danger { color: var(--accent); }
        
        .big-command {
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            border: 2px solid var(--accent-green);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            text-align: center;
        }
        
        .big-command code {
            font-size: 1.3rem;
            color: var(--accent-green);
            background: transparent;
        }
        
        .checklist {
            list-style: none;
        }
        
        .checklist li {
            padding: 8px 0;
            padding-left: 30px;
            position: relative;
        }
        
        .checklist li::before {
            content: '‚òê';
            position: absolute;
            left: 0;
            color: var(--accent-yellow);
        }
        
        .nav {
            background: var(--bg-card);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        
        .nav a {
            color: var(--accent-green);
            text-decoration: none;
            margin-right: 20px;
        }
        
        .nav a:hover { text-decoration: underline; }
        
        .toc {
            background: var(--bg-card);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }
        
        .toc ul {
            list-style: none;
            columns: 2;
        }
        
        .toc li { padding: 5px 0; }
        
        .toc a {
            color: var(--text);
            text-decoration: none;
        }
        
        .toc a:hover { color: var(--accent-green); }
        
        .ground-truth {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .ground-truth .item {
            background: var(--bg-card);
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }
        
        .ground-truth .item .value {
            font-size: 2rem;
            color: var(--accent-green);
            font-weight: bold;
        }
        
        .ground-truth .item .label {
            color: var(--text-dim);
            font-size: 0.9rem;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="nav">
            <a href="index.html">‚Üê Back to Index</a>
            <a href="DOC_MAINTENANCE.html">Doc Maintenance Guide</a>
            <a href="tables.html">Tables</a>
        </div>
        
        <h1>üîç BS DETECTOR</h1>
        <p class="subtitle">Verify LLM work before accepting it. Trust, but verify.</p>
        
        <div class="toc">
            <h3>Contents</h3>
            <ul>
                <li><a href="#quick-start">Quick Start - One Command</a></li>
                <li><a href="#ground-truth">Ground Truth Values</a></li>
                <li><a href="#five-commands">The 5-Command BS Test</a></li>
                <li><a href="#questions">Questions to Ask LLMs</a></li>
                <li><a href="#red-flags">Red Flags Checklist</a></li>
                <li><a href="#code-completeness">Code Completeness Check</a></li>
                <li><a href="#accountability">LLM Accountability Contract</a></li>
                <li><a href="#commands">Command Reference</a></li>
            </ul>
        </div>
        
        <!-- QUICK START -->
        <h2 id="quick-start">üöÄ Quick Start - One Command</h2>
        
        <p>Before accepting ANY package from an LLM, run this:</p>
        
        <div class="big-command">
            <code>python scripts/pre_delivery.py</code>
        </div>
        
        <div class="card green">
            <h3>If it shows "PASS"</h3>
            <p>‚úÖ The package is verified and ready. Accept it.</p>
        </div>
        
        <div class="card red">
            <h3>If it shows "FAIL"</h3>
            <p>‚ùå The LLM broke something. Show them the error output and demand a fix.</p>
        </div>
        
        <!-- GROUND TRUTH -->
        <h2 id="ground-truth">üìä Ground Truth Values</h2>
        
        <p class="warning">‚ö†Ô∏è MEMORIZE THESE. If an LLM gives different numbers, they're wrong.</p>
        
        <div class="ground-truth">
            <div class="item">
                <div class="value">59</div>
                <div class="label">Total Tables</div>
            </div>
            <div class="item">
                <div class="value">33</div>
                <div class="label">Dimension Tables</div>
            </div>
            <div class="item">
                <div class="value">24</div>
                <div class="label">Fact Tables</div>
            </div>
            <div class="item">
                <div class="value">2</div>
                <div class="label">QA Tables</div>
            </div>
            <div class="item">
                <div class="value">17</div>
                <div class="label">Total Goals</div>
            </div>
            <div class="item">
                <div class="value">4</div>
                <div class="label">Games Tracked</div>
            </div>
        </div>
        
        <h3>Goals Per Game</h3>
        <table>
            <tr><th>Game ID</th><th>Date</th><th>Matchup</th><th>Score</th><th>Goals</th></tr>
            <tr><td>18969</td><td>Sep 7, 2025</td><td>Platinum Group vs COS Velodrome</td><td>4-3</td><td class="highlight">7</td></tr>
            <tr><td>18977</td><td>Sep 14, 2025</td><td>HollowBrook Dental vs COS Velodrome</td><td>2-4</td><td class="highlight">6</td></tr>
            <tr><td>18981</td><td>Sep 28, 2025</td><td>Nelson & Company vs COS Velodrome</td><td>2-1</td><td class="highlight">3</td></tr>
            <tr><td>18987</td><td>Oct 5, 2025</td><td>OUTCAN Outlaws vs COS Velodrome</td><td>0-1</td><td class="highlight">1</td></tr>
        </table>
        
        <div class="card red">
            <h3>‚ö†Ô∏è CRITICAL: Goal Counting Rule</h3>
            <pre>event_type='Goal' AND event_detail='Goal_Scored'</pre>
            <p class="danger"><strong>Shot_Goal is the SHOT, not the goal!</strong></p>
            <p>If an LLM counts Shot_Goal as goals, they will get wrong numbers.</p>
        </div>
        
        <!-- 5 COMMANDS -->
        <h2 id="five-commands">üß™ The 5-Command BS Test</h2>
        
        <p>Copy and paste this ENTIRE block to any LLM:</p>
        
        <div class="card">
            <pre>STOP. Run these 5 commands and show me the COMPLETE output of each:

rm -rf data/output/*
python -m src.etl_orchestrator full 2>&1 | tail -30
ls data/output/*.csv | wc -l
python -c "import pandas as pd; df=pd.read_csv('data/output/fact_events.csv'); print('Goals:', len(df[(df['event_type']=='Goal') & (df['event_detail']=='Goal_Scored')]))"
python -m pytest tests/test_etl.py 2>&1 | tail -10

DO NOT paraphrase. DO NOT skip any command. Show raw output.</pre>
        </div>
        
        <h3>What to Expect</h3>
        <table>
            <tr><th>Command</th><th>Must Show</th><th>Red Flag</th></tr>
            <tr><td><code>rm -rf</code></td><td>(no output)</td><td>Any error</td></tr>
            <tr><td><code>etl_orchestrator</code></td><td>"ETL complete" or similar</td><td>Any Python error/traceback</td></tr>
            <tr><td><code>wc -l</code></td><td><span class="highlight">59</span></td><td>0 or different number</td></tr>
            <tr><td>Goals count</td><td><span class="highlight">Goals: 17</span></td><td>Different number or error</td></tr>
            <tr><td>pytest</td><td>X passed with no FAILED</td><td>Any FAILED tests</td></tr>
        </table>
        
        <!-- QUESTIONS -->
        <h2 id="questions">‚ùì Questions to Ask LLMs</h2>
        
        <h3>Before They Start (Knowledge Check)</h3>
        <table>
            <tr><th>Question</th><th>Correct Answer</th><th>Red Flags</th></tr>
            <tr>
                <td>How do you count goals?</td>
                <td><code>event_type='Goal' AND event_detail='Goal_Scored'</code></td>
                <td>"Shot_Goal", "just event_type='Goal'"</td>
            </tr>
            <tr>
                <td>How many tables?</td>
                <td>59 (59 (33 dim, 24 fact, 2 qa))</td>
                <td>61, 62, 130+, anything different</td>
            </tr>
            <tr>
                <td>Who is the scorer?</td>
                <td><code>event_player_1</code></td>
                <td>"event_player_2", "scorer column"</td>
            </tr>
            <tr>
                <td>How to run ETL?</td>
                <td><code>python -m src.etl_orchestrator full</code></td>
                <td>"python etl.py", "python base_etl.py"</td>
            </tr>
            <tr>
                <td>Which games are tracked?</td>
                <td>18969, 18977, 18981, 18987</td>
                <td>Different IDs or wrong count</td>
            </tr>
        </table>
        
        <h3>After They Claim a Fix</h3>
        <div class="card yellow">
            <pre>You changed code. Now prove it works:
rm -rf data/output/* && python -m src.etl_orchestrator full && ls data/output/*.csv | wc -l

Show me the output.</pre>
        </div>
        
        <h3>The Nuclear Question</h3>
        <div class="card red">
            <pre>Without running any commands, tell me:
1. How many tables does a fresh ETL run produce?
2. How many total goals across all 4 games?
3. What's the command to run the full ETL?

Now run the commands to verify your answers match reality.</pre>
            <p>If their answers don't match what the commands produce = <strong>BULLSHIT</strong></p>
        </div>
        
        <!-- RED FLAGS -->
        <h2 id="red-flags">üö® Red Flags Checklist</h2>
        
        <p class="danger">STOP the LLM immediately if you see any of these:</p>
        
        <table>
            <tr><th>#</th><th>Red Flag</th><th>What It Means</th></tr>
            <tr><td>1</td><td>Files getting SMALLER after "updates"</td><td>They deleted working code</td></tr>
            <tr><td>2</td><td>"I'll rewrite this from scratch"</td><td>They're about to break everything</td></tr>
            <tr><td>3</td><td>Creating new files instead of editing</td><td>They don't understand the codebase</td></tr>
            <tr><td>4</td><td>Version numbers going backwards</td><td>Using old/wrong docs</td></tr>
            <tr><td>5</td><td>No verification before delivery</td><td>They didn't test their changes</td></tr>
            <tr><td>6</td><td>Goal counts changing</td><td>Broke the goal counting logic</td></tr>
            <tr><td>7</td><td>Table counts changing unexpectedly</td><td>Broke the ETL pipeline</td></tr>
            <tr><td>8</td><td>"I'll simplify this"</td><td>About to delete working code</td></tr>
            <tr><td>9</td><td>Multiple "fixes" for same issue</td><td>Don't understand the problem</td></tr>
            <tr><td>10</td><td>Large code blocks without explanation</td><td>Hiding broken logic</td></tr>
        </table>
        
        <!-- CODE COMPLETENESS -->
        <h2 id="code-completeness">üìù Code Completeness Check</h2>
        
        <h3>Instant Code Red Flags</h3>
        <table>
            <tr><th>Pattern</th><th>Problem</th></tr>
            <tr><td><code># ... existing code ...</code></td><td>Incomplete - hiding parts</td></tr>
            <tr><td><code># TODO:</code></td><td>Unfinished work</td></tr>
            <tr><td><code># FIXME:</code></td><td>Known bugs left in</td></tr>
            <tr><td><code>pass</code> (in real functions)</td><td>Placeholder, not implemented</td></tr>
            <tr><td><code>raise NotImplementedError</code></td><td>Skeleton code</td></tr>
            <tr><td>"Add this to your file"</td><td>Patch, not complete file</td></tr>
            <tr><td>"Replace lines 50-100 with"</td><td>Fragile patch approach</td></tr>
            <tr><td>"You'll also need to..."</td><td>Hidden dependencies</td></tr>
            <tr><td>"Should work" / "Try this"</td><td>Untested</td></tr>
        </table>
        
        <h3>Root Cause vs Patchwork</h3>
        
        <div class="card green">
            <h3>‚úÖ ROOT CAUSE FIX (Good)</h3>
            <ul>
                <li>Fixes the actual source of the problem</li>
                <li>Changes are minimal and surgical</li>
                <li>Explains WHY the bug existed</li>
                <li>Future similar issues won't occur</li>
            </ul>
            <p><em>Example: "The bug was in line 245 where we used 'Period' instead of 'period' after the rename on line 880"</em></p>
        </div>
        
        <div class="card red">
            <h3>‚ùå PATCHWORK FIX (Bad)</h3>
            <ul>
                <li>Adds code to work around the symptom</li>
                <li>Creates new functions/files to "handle" the issue</li>
                <li>Doesn't explain root cause</li>
                <li>Similar bugs will keep appearing</li>
            </ul>
            <p><em>Example: "I added a try/except to catch the error" or "I created a new function to handle this case"</em></p>
        </div>
        
        <!-- ACCOUNTABILITY -->
        <h2 id="accountability">üìú LLM Accountability Contract</h2>
        
        <div class="card">
            <h3>Rules LLMs MUST Follow</h3>
            <ol>
                <li>NEVER create a package without running <code>python scripts/pre_delivery.py</code></li>
                <li>NEVER claim success without showing the full output</li>
                <li>NEVER manually zip files</li>
                <li>NEVER modify <code>config/IMMUTABLE_FACTS.json</code> without explicit permission</li>
                <li>If pre_delivery.py fails, FIX THE ROOT CAUSE - do not modify the script to make it pass</li>
            </ol>
        </div>
        
        <h3>Before Accepting ANY Package, Verify:</h3>
        <ul class="checklist">
            <li>LLM ran <code>python scripts/pre_delivery.py</code> with exit code 0</li>
            <li>No files got significantly smaller</li>
            <li>Changes were surgical edits (not full rewrites)</li>
            <li>LLM explained the root cause of any bugs fixed</li>
            <li>Goal count is 17</li>
            <li>Table count is 59</li>
            <li>Package includes MANIFEST.json</li>
        </ul>
        
        <!-- COMMANDS -->
        <h2 id="commands">‚å®Ô∏è Command Reference</h2>
        
        <table>
            <tr><th>Command</th><th>Purpose</th></tr>
            <tr><td><code>python scripts/pre_delivery.py</code></td><td>Full verification + package creation (12 phases)</td></tr>
            <tr><td><code>python scripts/pre_delivery.py --quick --reason "X"</code></td><td>Doc-only changes (skip ETL)</td></tr>
            <tr><td><code>python scripts/pre_delivery.py --dry-run</code></td><td>Preview what would happen</td></tr>
            <tr><td><code>python -m pytest tests/test_tier1_blocking.py -v</code></td><td>Run Tier 1 tests (32 blocking)</td></tr>
            <tr><td><code>python -m pytest tests/test_tier2_warning.py -v</code></td><td>Run Tier 2 tests (17 warning)</td></tr>
            <tr><td><code>python scripts/utilities/schema_snapshot.py --compare</code></td><td>Compare schema to snapshot</td></tr>
            <tr><td><code>python scripts/utilities/validate_input.py</code></td><td>Validate raw Excel files</td></tr>
            <tr><td><code>python scripts/utilities/doc_consistency.py --status</code></td><td>Show current version info</td></tr>
        </table>
        
        <h3>Tiered Test System</h3>
        <table>
            <tr><th>Tier</th><th>File</th><th>Tests</th><th>Effect</th></tr>
            <tr><td>1</td><td><code>test_tier1_blocking.py</code></td><td>32</td><td class="danger">BLOCKS delivery if any fail</td></tr>
            <tr><td>2</td><td><code>test_tier2_warning.py</code></td><td>17</td><td class="warning">Logged as warnings</td></tr>
            <tr><td>3</td><td><code>test_tier3_future.py</code></td><td>-</td><td>Skipped (future features)</td></tr>
        </table>
        
        <div class="card">
            <h3>Manual Verification Commands</h3>
            <pre># Check table count
ls data/output/*.csv | wc -l  # Should be 59

# Check goal count
python -c "import pandas as pd; df=pd.read_csv('data/output/fact_events.csv'); print(len(df[(df['event_type']=='Goal') & (df['event_detail']=='Goal_Scored')]))"
# Should be 17

# Run tests
python -m pytest tests/test_etl.py -v

# Check file sizes (detect truncation)
wc -l LLM_REQUIREMENTS.md  # Should be 500+ lines
wc -l src/core/base_etl.py  # Should be 2500+ lines</pre>
        </div>
        
        <hr style="margin: 40px 0; border-color: var(--border);">
        <p style="text-align: center; color: var(--text-dim);">
            BenchSight v13.18 | Last Updated: January 7, 2026
        </p>
    </div>
</body>
</html>
