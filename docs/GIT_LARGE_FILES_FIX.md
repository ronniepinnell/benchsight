# Fixing GitHub "File Too Large" Error

## Problem

GitHub has a 100MB file size limit. If you try to push files larger than this, you'll get an error like:
```
remote: error: File data/output/fact_events.csv is 124.00 MB; this exceeds GitHub's file size limit of 100.00 MB
```

## Solution Options

### Option 1: Use Git LFS (Recommended for Large Data Files)

Git LFS (Large File Storage) stores large files outside the main repository.

**1. Install Git LFS:**
```bash
# macOS
brew install git-lfs

# Or download from: https://git-lfs.github.com/
```

**2. Initialize Git LFS:**
```bash
git lfs install
```

**3. Track large file types:**
```bash
git lfs track "*.xlsx"
git lfs track "*.csv"
git lfs track "data/output/*.csv"
git lfs track "data/raw/**/*.xlsx"
```

**4. Add .gitattributes:**
```bash
git add .gitattributes
git commit -m "Add Git LFS tracking for large files"
```

### Option 2: Exclude Large Files from Git (Recommended for Generated Files)

If files are generated (like ETL output), exclude them from git entirely.

**1. Add to .gitignore:**
```
# Data output files (generated by ETL)
data/output/*.csv
data/output/*.json

# Raw data files (too large)
data/raw/games/**/*.xlsx
data/raw/**/*.xlsx
```

**2. Remove from git tracking (but keep local files):**
```bash
git rm --cached data/output/*.csv
git rm --cached data/raw/games/**/*.xlsx
```

**3. Commit:**
```bash
git add .gitignore
git commit -m "Exclude large data files from git"
```

### Option 3: Remove Large Files from Git History

If large files are already in git history, you need to remove them:

**1. Use git filter-branch (destructive - rewrites history):**
```bash
# Remove specific files from all commits
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch data/output/*.csv" \
  --prune-empty --tag-name-filter cat -- --all
```

**2. Force push (WARNING: This rewrites history):**
```bash
git push origin --force --all
```

**⚠️ Warning:** Only do this if you're the only one working on the repo, or coordinate with your team.

### Option 4: Use BFG Repo-Cleaner (Easier than filter-branch)

**1. Download BFG:**
```bash
brew install bfg
# Or download from: https://rtyley.github.io/bfg-repo-cleaner/
```

**2. Remove large files:**
```bash
# Create a fresh clone
git clone --mirror your-repo.git

# Remove files larger than 10MB
bfg --strip-blobs-bigger-than 10M your-repo.git

# Clean up
cd your-repo.git
git reflog expire --expire=now --all
git gc --prune=now --aggressive

# Push
git push
```

## Quick Fix Script

We've created a script to help:

```bash
./scripts/fix_git_large_files.sh
```

This will:
1. Remove large files from git tracking
2. Set up Git LFS if available
3. Show you what needs to be committed

## Recommended Approach for BenchSight

**For this project, I recommend:**

1. **Exclude generated files** (data/output/*.csv) - these are created by ETL
2. **Use Git LFS for source data** (data/raw/*.xlsx) - if you need to track them
3. **Exclude node_modules and build files** - already in .gitignore

**Steps:**
```bash
# 1. Remove large files from tracking
git rm --cached data/output/*.csv
git rm --cached data/raw/games/**/*.xlsx

# 2. Commit .gitignore
git add .gitignore .gitattributes
git commit -m "Exclude large data files from git"

# 3. Push
git push
```

## Current Large Files in Your Repo

Based on analysis, these files are large:
- `ui/dashboard/node_modules/@next/swc-darwin-arm64/next-swc.darwin-arm64.node` (124MB)
- `data/output/fact_event_players.csv` (7MB)
- `data/output/fact_events.csv` (5MB)
- `data/raw/games/*/tracking.xlsx` (4-5MB each)

**Recommendation:**
- Exclude `data/output/*.csv` (generated files)
- Exclude `node_modules/` (already should be ignored)
- Use Git LFS for `data/raw/*.xlsx` if you need to track them
